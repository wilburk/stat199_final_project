---
title: "Final Project"
author: "kimchi-stew"
date: "May 4th, 2018"
output: github_document
---

### Load Packages & Data

```{r load-packages-data}
library(stringr)
library(stringi)
library(tidyverse)
library(broom)
library(splitstackshape)
library(rpart)
library(rpart.plot)
library(RColorBrewer)
library(rlist)
library(randomForest)
library(miscTools)
library(ggplot2)
library(ggmap)
library(maps)
library(mapdata)

set.seed(415)
# run load-data.R first
food <- read_csv("data/food.csv")
food_attr <- read_csv("data/food-attributes.csv") 
food_hours <- read_csv("data/food-hours.csv")

food_attr <- food_attr %>% 
  select(-starts_with("DietaryRestrictions"))

food_attr_col <- colnames(food_attr) %>% 
  as.data.frame() %>%
  mutate(cols = str_replace(., "-", "_")) %>% 
  select(-.) %>% 
  pull()

colnames(food_attr) <- food_attr_col

```

```{r initial_visualizations}

food_stars <- food %>%
  count(stars) %>% 
  arrange(desc(stars))
food_stars

ggplot(food_stars,aes(stars,n)) +
  geom_col()+
  labs(title = "Distribuction of star ratings")

food %>%
  count(state) %>% 
  arrange(desc(n))

food %>%
  summarise(mean = mean(stars),median = median(stars))

food %>% 
  cSplit("categories", direction = "tall", sep = ",") %>% 
  count(categories) %>% 
  arrange(desc(n))


```

```{r map}
usa <- map_data("usa")
world_map <- map_data("world")
p <- ggplot() + coord_fixed() +
  xlab("") + ylab("")

#Add map to base plot
base_world_messy <- p + geom_polygon(data=world_map, aes(x=long, y=lat, group=group), 
                               colour="black", fill="black")
cleanup <- 
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), 
        panel.background = element_rect(fill = 'white', colour = 'white'), 
        axis.line = element_line(colour = "white"), legend.position="none",
        axis.ticks=element_blank(), axis.text.x=element_blank(),
        axis.text.y=element_blank())

base_world <- base_world_messy + cleanup

food <- food %>% 
  filter(longitude < 100 & longitude >-130) %>% 
  filter(business_id != "vBxK_MAGuy8eWL_CCfUCUQ") %>% 
  filter(latitude > -20 | latitude < -45)

map_data <- 
  base_world +
  geom_point(data=food, 
             aes(x=longitude, y=latitude), colour="red", 
             fill="Pink",pch=21, size=5, alpha=I(0.5))
map_data


```


```{r recode_variables, message=FALSE}

### this block counts up non-null values 

# create new var to represent if at least one of the subvalues is true
food_attr_temp <- food_attr %>% 
  select(-business_id) %>% 
  mutate(BusinessParking =  BusinessParking.garage	  == TRUE	|	 	
                            BusinessParking.street    == TRUE |				
                            BusinessParking.validated	== TRUE	|	 
                            BusinessParking.lot       == TRUE |	
                            BusinessParking.valet     == TRUE,
         Music =  Music.dj                == TRUE |				
                  Music.background_music	== TRUE |			
                  Music.no_music		      == TRUE |		
                  Music.karaoke	          == TRUE |			
                  Music.live              == TRUE | 
                  Music.video             == TRUE |			
                  Music.jukebox	          == TRUE ,	
         Ambience = Ambience.romantic	== TRUE |			
                    Ambience.intimate	== TRUE |			
                    Ambience.classy		== TRUE |		
                    Ambience.hipster	== TRUE |			
                    Ambience.divey		== TRUE |		
                    Ambience.touristy	== TRUE |			
                    Ambience.trendy		== TRUE |		
                    Ambience.upscale  == TRUE |
                    Ambience.casual		== TRUE,	
         BestNights = BestNights.monday	  	== TRUE |	
                      BestNights.tuesday		== TRUE |			
                      BestNights.friday			== TRUE |		
                      BestNights.wednesday	== TRUE |				
                      BestNights.thursday		== TRUE |			
                      BestNights.sunday			== TRUE |		
                      BestNights.saturday		== TRUE,	
         GoodForMeal =  GoodForMeal.dessert   == TRUE |		
                        GoodForMeal.latenight	== TRUE |
                        GoodForMeal.lunch		  == TRUE |			
                        GoodForMeal.dinner		== TRUE |			
                        GoodForMeal.breakfast	== TRUE |		
                        GoodForMeal.brunch		== TRUE)	

# recode null and non null with 0/1
food_attr_temp[is.na(food_attr_temp)] <- 0
food_attr_temp[food_attr_temp != 0] <- 1

# sum up to get non null values
food_attr_counts <- food_attr_temp %>% 
  summarise_all(funs(sum(. == 1))) %>% 
  gather(attribute, total, 1:ncol(.)) %>% 
  arrange(desc(total))

# for categories broken into multiple columns, get frequency of occurences
level_props <- data.frame(attribute = colnames(food_attr)) %>% 
  filter(str_detect(attribute, "\\.")) %>% 
  inner_join(food_attr_counts, by = "attribute") %>% 
  mutate(attribute_parent = str_remove(attribute, "\\..+"),
         attribute = str_remove(attribute, ".+\\.")) %>%
  rename(subtotal = total) %>% 
  inner_join(food_attr_counts, by = c("attribute_parent" = "attribute")) %>% 
  mutate(prop = subtotal / total) %>% 
  mutate(subtotal = case_when(attribute == "hipster" ~ as.double(858),
                              attribute != "hipster" ~ as.double(subtotal))) %>% 
  arrange(attribute_parent, desc(prop)) 

# manually break tie
level_props[4,2] <- 858
level_props[4,5] <- 0.03737

# for these multi-column attributes, this tells us how many columns are usually true in any row
data.frame(attribute = colnames(food_attr)) %>% 
  filter(str_detect(attribute, "\\.")) %>% 
  inner_join(food_attr_counts, by = "attribute") %>% 
  mutate(attribute_parent = str_remove(attribute, "\\..+")) %>%
  rename(subtotal = total) %>% 
  inner_join(food_attr_counts, by = c("attribute_parent" = "attribute")) %>% 
  mutate(prop = subtotal / total) %>% 
  arrange(attribute_parent, desc(prop)) %>% 
  group_by(attribute_parent) %>% 
  summarise(undisjoint_factor = sum(subtotal) / median(total))

```


```{r count_columns_to_find_variables_for_analysis}

### this code block merges the multi column attribues into single columns
### and if there are multiple values follows a protocol (min, max, or prob) 
### to determine which value should represent the row
### e.g. the merged BestNights column might have `wednesday,friday,sunday`,
### and if `wednesday` appears least in the dataset, the min protocol 
### would reduce this to `wednesday`

# get the names of the multi-column attributes
lst <- food_attr %>% 
  select(contains(".")) %>% 
  colnames() 

# this function changes the formatting of the multicolumn attributes 
# true values take on the name of the column, false values are periods
convert_dot <- function(col_name) {
  col_name_short <- str_remove(col_name, ".+\\.")
  index <- grep(col_name, colnames(food_attr))
  col <- food_attr[index]
  col[col == TRUE] <- paste0(col_name_short, ",")
  col[col == FALSE] <- "."
  return(col)
}

# run the function 
food_attr_convert <- purrr::map(lst, convert_dot) %>% 
  as.data.frame()

# aggregate the columnn by pasting together the variable values;
# since true values are the name of the column, this column tells us the names
# of the sub attributes that are true... formatting at the end
food_attr_convert <- food_attr_convert %>% 
  mutate(aggBusinessParking =  paste0(BusinessParking.garage,	 	
                                      BusinessParking.street,			
                                      BusinessParking.validated,	 
                                      BusinessParking.lot,
                                      BusinessParking.valet, sep=""),
         aggMusic = paste0(Music.dj,				
                           Music.background_music,		
                           Music.no_music,
                           Music.karaoke	,
                           Music.live,
                           Music.video,			
                           Music.jukebox, sep=""),
         aggAmbience = paste0(Ambience.romantic,
                              Ambience.intimate,		
                              Ambience.classy	,	
                              Ambience.hipster,		
                              Ambience.divey	,	
                              Ambience.touristy,		
                              Ambience.trendy	,	
                              Ambience.upscale,
                              Ambience.casual, sep=""),
         aggBestNights = paste0(BestNights.monday	 ,	
                                BestNights.tuesday		,	
                                BestNights.friday			,
                                BestNights.wednesday	,		
                                BestNights.thursday		,	
                                BestNights.sunday			,
                                BestNights.saturday, sep=""),
         aggGoodForMeal = paste0(GoodForMeal.dessert,		
                                 GoodForMeal.latenight,
                                 GoodForMeal.lunch		  ,	
                                 GoodForMeal.dinner		,	
                                 GoodForMeal.breakfast	,
                                 GoodForMeal.brunch, sep="")) %>% 
  select(-contains(".")) %>% 
  mutate_all(funs(str_replace_all(.,",+", ","))) %>% 
  mutate_all(funs(str_replace_all(., "[NA]+", "NA"))) %>% 
  mutate_all(funs(str_remove_all(., "\\.NA|NA\\."))) %>% 
  mutate_all(funs(str_replace_all(., "^\\.+$", "None"))) %>% 
  mutate_all(funs(str_remove_all(., "\\.+"))) %>% 
  mutate_all(funs(str_remove(.,"^,"))) %>% 
  mutate_all(funs(str_remove(.,",$")))

# turn "NA" into NA
food_attr_convert[food_attr_convert == "NA"] <- NA

### PROBLEM: too many collisions between variables - need to reduce to one value; don't want to eliminate too much information
### SOLUTION1: choose in order of frequency, low to high
### IMPLEMENTATION: iterate through, call function: if (numberofcommas + 1) > 1: split into vector, for each element in vector
### PROBLEM: if all slightly equal numbers but still collisions, some vals might not get seen

# min protocol: picks the least frequent value
pick_index_min <- function(freq_vect) {
  return(grep(min(freq_vect), freq_vect))
}

# max protocol: picks the most frequent value
pick_index_max <- function(freq_vect) {
  return(grep(max(freq_vect), freq_vect))
}

# prob protocol: picks the value probabilistically according to frequency so that
# same combinations of values aren't always the same
pick_index_prob <- function(freq_vect) {
  ord_vect <- sort(freq_vect)
  total <- reduce(freq_vect, sum)
  ord_vect_prob <- sapply(ord_vect, function(x) x/total)
  rev_vect_prob <- sort(ord_vect_prob, decreasing = TRUE)
  for (i in 2:length(rev_vect_prob)){
    rev_vect_prob[[i]] <- rev_vect_prob[[i]] + rev_vect_prob[[i-1]]
  }
  rand <- runif(1)
  ind <- which(sapply(rev_vect_prob, function (x) x > rand))[[1]]
  return(grep(ord_vect[[ind]],freq_vect))
}

# this function reduces a row of multiple values to a single value
# according to some protocol, in this case min
my_reduce <- function(col) {

  for (i in 1:length(col)) {
    val_list <- col[[i]]
    if (is.na(val_list) | val_list == "None" | !str_detect(val_list, ",")) {
      col[[i]] <- val_list
    } else {
      vals <- unlist(str_split(val_list, ","))
      freq_vect <- c()
      for (val in vals) {
        freq <- level_props %>%
          filter(attribute == val) %>%
          select(subtotal) %>%
          pull()
        freq_vect <- c(freq_vect, freq)
      }
      index <- pick_index_min(freq_vect)
      col[[i]] <- vals[index]
    }
  }
  return(col)
}

# apply the function
food_attr_reduce <- food_attr_convert %>% 
  mutate_all(funs(my_reduce))

```



```{r prep-data-set}

column_list <- food_attr_temp %>% 
  select(1:65) %>% 
  select(-contains(".")) %>% 
  summarise_all(funs(sum(. == 1))) %>% 
  gather(attribute, total, 1:ncol(.)) %>% 
  arrange(desc(total)) %>% 
  filter(total > 10000) %>% 
  pull(attribute)

test_df <- food_attr[c(column_list)] %>% 
  cbind(food_attr_reduce)

test_columns <- purrr::map(colnames(test_df), function(x) convert(x,food_attr)) %>% 
  as.data.frame() %>% 
  unite(attr,sep = "", remove = TRUE) %>% 
  count(attr) %>% 
  mutate(num_attr = str_count(attr, ","),
          opt_score = num_attr*n, 
          group = i) %>% 
  filter(opt_score > 0) %>% 
  arrange(desc(num_attr * n)) %>% 
  pull(attr) %>% 
  sapply(function(x) unlist(strsplit(x, split=",")))
```



```{r find-optimal-column}
cols_eval <- function(col_names, tbl) {
  food_attr_local <- tbl[col_names]
  output <- food_attr_local %>% 
    drop_na() %>% 
    summarise(n = nrow(.),
              attr = paste0(col_names, collapse = ",")) %>% 
    mutate(num_attr = length(col_names),
           opt_score = n*num_attr)
  
  return(output)
}

powerset <- function(vect) {
  total <- character()
  range <- c(((6 * length(vect)) %/% 10):length(vect))
  print(range)
  for (m in range) {
    x <- combn(vect, m, simplify = FALSE)
    total <- append(total,x)
  }
  return(total)
}

find_best_cols <- function(tbl) {
  #pwrset <- powerset(colnames(tbl))
  result <- map_df(test_columns, function(x) cols_eval11(x,tbl)) %>%               
    arrange(desc(opt_score)) %>% 
    select(attr, opt_score, n, num_attr)
  return(result)
}

all_cols <- find_best_cols11(test_df[1:22])
all_cols %>%
  ggplot(aes(x = num_attr, y = n, z = opt_score, color = (n*num_attr))) +
  geom_point(size = 4, alpha = 1) +
  stat_function(fun = function(x) 412555/(.5*x), color = "red") +
  stat_function(fun = function(x) 412555/x, color = "red") +
  stat_function(fun = function(x) 412555/(2*x), color = "red") +
  stat_function(fun = function(x) 412555/(4*x), color = "red") +
  stat_function(fun = function(x) 412555/(8*x), color = "red") +
  scale_color_distiller(palette = "Blues", direction = 1) + 
  theme_minimal() + 
  ylim(0,75000) +
  labs(color = "Optimization Function", y = "Number of Rows", x = "Number of Attributes", title = "Finding best combination of columns", subtitle = "Optimizing for number of rows and number of attributes")

(candidate_columns <- all_cols %>% 
  top_n(3, opt_score) %>% 
  pull(attr))

```

```{r final-dataset}

# use the significant columns found to trim down dataset
# this puts together the significant columns we found with our new merged columns, drop NA's
food_attr_mod_2 <- food_attr %>% 
  cbind(food_attr_reduce) %>% 
  select(business_id, BusinessAcceptsCreditCards,RestaurantsPriceRange2,GoodForKids,BikeParking,Alcohol,HasTV,NoiseLevel,RestaurantsAttire,RestaurantsGoodForGroups,Caters,WiFi,RestaurantsReservations,RestaurantsTakeOut, aggBusinessParking, aggAmbience, aggGoodForMeal) %>% 
  drop_na()

# this function reduces a row of multiple values to a single value
# according to some protocol, in this case max
my_reduce_2 <- function(col) {

  for (i in 1:length(col)) {
    val_list <- col[[i]]
    if (is.na(val_list) | val_list == "None" | !str_detect(val_list, ",")) {
      col[[i]] <- val_list
    } else {
      vals <- unlist(str_split(val_list, ","))
      freq_vect <- c()
      for (val in vals) {
        freq <- category_counts %>%
          filter(categories == val) %>%
          select(n) %>%
          pull()
        freq_vect <- c(freq_vect, freq)
      }
      index <- pick_index_max(freq_vect)
      col[[i]] <- vals[index]
    }
  }
  return(col)
}

# reduce the categories variable
food$categories <- my_reduce_2(food$categories)

# pull the top 50 categories
large_categories_list <- food %>% 
  count(categories) %>% 
  arrange(desc(n)) %>% 
  head(50) %>% 
  pull(categories)

# filter by the top 50 categories
food_reduce <- food %>% 
  filter(categories %in% large_categories_list)

# merge the business info dataset with the business attributes 
food_reduce <- food_reduce %>% 
  inner_join(food_attr_mod_2, by = "business_id")

# turn character columns into factors
cols = c("Alcohol", "NoiseLevel", "RestaurantsAttire", "WiFi", "aggBusinessParking", "aggAmbience", "aggGoodForMeal", "categories")
food_reduce[cols] <- lapply(food_reduce[cols], factor)

# create training set
train_full <- food_reduce %>% 
  head(9*nrow(food_reduce)/10)

# create test set
test_full <- food_reduce %>% 
  tail(1*nrow(food_reduce)/10)

```

```{r linear regression}

#run linear analysis 
lm_food <- lm(stars ~ RestaurantsPriceRange2 + categories + BusinessAcceptsCreditCards + Alcohol +  HasTV + NoiseLevel +  RestaurantsGoodForGroups + Caters + WiFi + aggBusinessParking + aggAmbience + aggGoodForMeal + review_count + BikeParking + GoodForKids + RestaurantsReservations + RestaurantsTakeOut + RestaurantsAttire + RestaurantsGoodForGroups,data = food_reduce)

AIC(lm_food)
summary(lm_food)$adj.r.squared
```

```{r random_forest}

# run random forest
fit_full <- randomForest(stars ~  RestaurantsPriceRange2 + categories + BusinessAcceptsCreditCards + Alcohol +  HasTV + NoiseLevel +  RestaurantsGoodForGroups + Caters + WiFi + aggBusinessParking + aggAmbience + aggGoodForMeal + review_count + BikeParking + GoodForKids + RestaurantsReservations + RestaurantsTakeOut + RestaurantsAttire + RestaurantsGoodForGroups, 
                    data=train_full, 
                    importance=TRUE,  
                    ntree=50)

# inspect which elements are important
varImpPlot(fit_full)

# get r^2
(r2 <- rSquared(test_full$stars, test_full$stars - predict(fit_full, test_full)))

# plot learning curve
plot(fit_full)

# get info on model
fit_full

# predict values on test set
predict_tbl <- predict(fit_full, test_full) %>% 
  as.data.frame()

# modify predict_tbl
colnames(predict_tbl) <- c("predicted_score")
for (i in 1:nrow(predict_tbl)){
  predict_tbl[i,"index"] <-  i 
}

# find rows with highest predicted stars in test set
predict_tbl %>% 
  top_n(1, predicted_score) %>% 
  pull() %>% 
  test_full[.,] %>% 
  select(-business_id, -address, -postal_code, -latitude, -longitude, -is_open)

```


```{r random_forest_func}

# this function performs the above analysis for any subset of the dataset
random_forest <- function(x){
  food_reduce <- food_reduce %>% 
    filter(categories == x)

  cols = c("Alcohol", "NoiseLevel", "RestaurantsAttire", "WiFi", "aggBusinessParking", "aggAmbience", "aggGoodForMeal", "categories")
  food_reduce[cols] <- lapply(food_reduce[cols], factor)
  
  train_full <- food_reduce %>% 
    head(9*nrow(food_reduce)/10)
  
  test_full <- food_reduce %>% 
    tail(1*nrow(food_reduce)/10)
  
  fit_full <- randomForest(stars ~  RestaurantsPriceRange2 + categories + BusinessAcceptsCreditCards + Alcohol +  HasTV + NoiseLevel +  RestaurantsGoodForGroups + Caters + WiFi + aggBusinessParking + aggAmbience + aggGoodForMeal + review_count + BikeParking + GoodForKids + RestaurantsReservations + RestaurantsTakeOut + RestaurantsAttire + RestaurantsGoodForGroups , 
                      data=train_full, 
                      importance=TRUE,  
                      ntree=200)
  
  r2 <- round(rSquared(test_full$stars, test_full$stars - predict(fit_full, test_full)),3) %>% 
    as.data.frame()
  
  colnames(r2) <- "r.squared" 
    
  predict_tbl <- predict(fit_full, test_full) %>% 
  data.frame()

  colnames(predict_tbl) <- c("predicted_score")
  for (i in 1:nrow(predict_tbl)){
    predict_tbl[i,"index"] <-  i 
  }

  # find rows with highest predicted stars in test set
  predict_tbl <- predict_tbl %>% 
    top_n(3, predicted_score) 
  
  output <- predict_tbl %>% 
    pull(index) %>% 
    test_full[.,] %>% 
    select(-business_id, -address, -postal_code, -latitude, -longitude, -is_open) 

  plot(fit_full, main = x)
  
  return(cbind(predict_tbl[1], r2, output))
  #return(as.data.frame(r2))

}


#Apply the function random forest to each element of the vector large_categories_list
categories_rows <-large_categories_list[1:20]
best_row <- purrr::map_df(categories_rows,random_forest)
best_row %>% 
  arrange(desc(r.squared), desc(predicted_score)) %>% 
  select(categories, everything())
```


```{r rpart regression tree}


fit <- rpart(stars ~ categories+BusinessAcceptsCreditCards+RestaurantsPriceRange2+GoodForKids+BikeParking+Alcohol+HasTV+NoiseLevel+RestaurantsAttire+RestaurantsGoodForGroups+Caters+WiFi+RestaurantsReservations+RestaurantsTakeOut+aggBusinessParking+aggAmbience+aggGoodForMeal, method = "anova", data = food_reduce)

printcp(fit) # display the results 
plotcp(fit) # visualize cross-validation results 
summary(fit) # detailed summary of splits

par(mfrow=c(1,2)) # two plots on one page 
rsq.rpart(fit) # visualize cross-validation results  

prune(fit, cp = 0.02)

plot(fit, uniform=TRUE, 
  	main="Regression Tree for Mileage ")
text(fit, use.n=TRUE, all=TRUE)

```






### EDA -- Katie
```{r}
library(mapdata)
library(maps)
library(klaR)
```
```{r}
which(food$address == "Green Valley Ranch Resort, 2309 Paseo Verde Pkwy")
food %>% 
  filter(longitude > 110)
```

```{r}
df <- na.omit(analysis)
df <- df %>% 
  mutate(RestaurantsPriceRange2 = case_when(
    RestaurantsPriceRange2 == 2 ~ "2",
    RestaurantsPriceRange2 == 1 ~ "1",
    RestaurantsPriceRange2 == 3 ~ "3",
    RestaurantsPriceRange2 == 4 ~ "4"
  ))
temp <- df[c(13,15)]
test <- kmodes(temp, 3, iter.max = 10, weighted = FALSE)
test
```
s