---
title: "Final Project"
author: "kimchi-stew"
date: "May 4th, 2018"
output: github_document
---

### Load Packages & Data

```{r load-packages-data}
library(stringr)
library(stringi)
library(tidyverse)
library(broom)
library(splitstackshape)
library(rpart)
library(rpart.plot)
library(RColorBrewer)
library(rlist)
library(randomForest)
library(miscTools)
library(ggplot2)
library(ggmap)
library(maps)
library(mapdata)

set.seed(415)
# run load-data.R first
food <- read_csv("data/food.csv")
food_attr <- read_csv("data/food-attributes.csv") 
food_hours <- read_csv("data/food-hours.csv")

food_attr <- food_attr %>% 
  select(-starts_with("DietaryRestrictions"))

food_attr_col <- colnames(food_attr) %>% 
  as.data.frame() %>%
  mutate(cols = str_replace(., "-", "_")) %>% 
  select(-.) %>% 
  pull()

colnames(food_attr) <- food_attr_col

```

```{r initial_visualizations}

food_stars <- food %>%
  count(stars) %>% 
  arrange(desc(stars))
food_stars

ggplot(food_stars,aes(stars,n)) +
  geom_col()+
  labs(title = "Distribuction of star ratings")

food %>%
  count(state) %>% 
  arrange(desc(n))

food %>%
  summarise(mean = mean(stars),median = median(stars))

food %>% 
  cSplit("categories", direction = "tall", sep = ",") %>% 
  count(categories) %>% 
  arrange(desc(n))


```

```{r map}
usa <- map_data("usa")
world_map <- map_data("world")
p <- ggplot() + coord_fixed() +
  xlab("") + ylab("")

#Add map to base plot
base_world_messy <- p + geom_polygon(data=world_map, aes(x=long, y=lat, group=group), 
                               colour="black", fill="black")
cleanup <- 
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), 
        panel.background = element_rect(fill = 'white', colour = 'white'), 
        axis.line = element_line(colour = "white"), legend.position="none",
        axis.ticks=element_blank(), axis.text.x=element_blank(),
        axis.text.y=element_blank())

base_world <- base_world_messy + cleanup

food <- food %>% 
  filter(longitude < 100 & longitude >-130) %>% 
  filter(business_id != "vBxK_MAGuy8eWL_CCfUCUQ") %>% 
  filter(latitude > -20 | latitude < -45)

map_data <- 
  base_world +
  geom_point(data=food, 
             aes(x=longitude, y=latitude), colour="red", 
             fill="Pink",pch=21, size=5, alpha=I(0.5))
map_data


```


```{r recode_variables, message=FALSE}

### this block counts up non-null values 

# create new var to represent if at least one of the subvalues is true
food_attr_temp <- food_attr %>% 
  select(-business_id) %>% 
  mutate(BusinessParking =  BusinessParking.garage	  == TRUE	|	 	
                            BusinessParking.street    == TRUE |				
                            BusinessParking.validated	== TRUE	|	 
                            BusinessParking.lot       == TRUE |	
                            BusinessParking.valet     == TRUE,
         Music =  Music.dj                == TRUE |				
                  Music.background_music	== TRUE |			
                  Music.no_music		      == TRUE |		
                  Music.karaoke	          == TRUE |			
                  Music.live              == TRUE | 
                  Music.video             == TRUE |			
                  Music.jukebox	          == TRUE ,	
         Ambience = Ambience.romantic	== TRUE |			
                    Ambience.intimate	== TRUE |			
                    Ambience.classy		== TRUE |		
                    Ambience.hipster	== TRUE |			
                    Ambience.divey		== TRUE |		
                    Ambience.touristy	== TRUE |			
                    Ambience.trendy		== TRUE |		
                    Ambience.upscale  == TRUE |
                    Ambience.casual		== TRUE,	
         BestNights = BestNights.monday	  	== TRUE |	
                      BestNights.tuesday		== TRUE |			
                      BestNights.friday			== TRUE |		
                      BestNights.wednesday	== TRUE |				
                      BestNights.thursday		== TRUE |			
                      BestNights.sunday			== TRUE |		
                      BestNights.saturday		== TRUE,	
         GoodForMeal =  GoodForMeal.dessert   == TRUE |		
                        GoodForMeal.latenight	== TRUE |
                        GoodForMeal.lunch		  == TRUE |			
                        GoodForMeal.dinner		== TRUE |			
                        GoodForMeal.breakfast	== TRUE |		
                        GoodForMeal.brunch		== TRUE)	

# recode null and non null with 0/1
food_attr_temp[is.na(food_attr_temp)] <- 0
food_attr_temp[food_attr_temp != 0] <- 1

# sum up to get non null values
food_attr_counts <- food_attr_temp %>% 
  summarise_all(funs(sum(. == 1))) %>% 
  gather(attribute, total, 1:ncol(.)) %>% 
  arrange(desc(total))

# for categories broken into multiple columns, get frequency of occurences
level_props <- data.frame(attribute = colnames(food_attr)) %>% 
  filter(str_detect(attribute, "\\.")) %>% 
  inner_join(food_attr_counts, by = "attribute") %>% 
  mutate(attribute_parent = str_remove(attribute, "\\..+"),
         attribute = str_remove(attribute, ".+\\.")) %>%
  rename(subtotal = total) %>% 
  inner_join(food_attr_counts, by = c("attribute_parent" = "attribute")) %>% 
  mutate(prop = subtotal / total) %>% 
  mutate(subtotal = case_when(attribute == "hipster" ~ as.double(858),
                              attribute != "hipster" ~ as.double(subtotal))) %>% 
  arrange(attribute_parent, desc(prop)) 

# manually break tie
level_props[4,2] <- 858
level_props[4,5] <- 0.03737

# for these multi-column attributes, this tells us how many columns are usually true in any row
data.frame(attribute = colnames(food_attr)) %>% 
  filter(str_detect(attribute, "\\.")) %>% 
  inner_join(food_attr_counts, by = "attribute") %>% 
  mutate(attribute_parent = str_remove(attribute, "\\..+")) %>%
  rename(subtotal = total) %>% 
  inner_join(food_attr_counts, by = c("attribute_parent" = "attribute")) %>% 
  mutate(prop = subtotal / total) %>% 
  arrange(attribute_parent, desc(prop)) %>% 
  group_by(attribute_parent) %>% 
  summarise(undisjoint_factor = sum(subtotal) / median(total))

```


```{r count_columns_to_find_variables_for_analysis}

### this code block merges the multi column attribues into single columns
### and if there are multiple values follows a protocol (min, max, or prob) 
### to determine which value should represent the row
### e.g. the merged BestNights column might have `wednesday,friday,sunday`,
### and if `wednesday` appears least in the dataset, the min protocol 
### would reduce this to `wednesday`

# get the names of the multi-column attributes
lst <- food_attr %>% 
  select(contains(".")) %>% 
  colnames() 

# this function changes the formatting of the multicolumn attributes 
# true values take on the name of the column, false values are periods
convert_dot <- function(col_name) {
  col_name_short <- str_remove(col_name, ".+\\.")
  index <- grep(col_name, colnames(food_attr))
  col <- food_attr[index]
  col[col == TRUE] <- paste0(col_name_short, ",")
  col[col == FALSE] <- "."
  return(col)
}

# run the function 
food_attr_convert <- purrr::map(lst, convert_dot) %>% 
  as.data.frame()

# aggregate the columnn by pasting together the variable values;
# since true values are the name of the column, this column tells us the names
# of the sub attributes that are true... formatting at the end
food_attr_convert <- food_attr_convert %>% 
  mutate(aggBusinessParking =  paste0(BusinessParking.garage,	 	
                                      BusinessParking.street,			
                                      BusinessParking.validated,	 
                                      BusinessParking.lot,
                                      BusinessParking.valet, sep=""),
         aggMusic = paste0(Music.dj,				
                           Music.background_music,		
                           Music.no_music,
                           Music.karaoke	,
                           Music.live,
                           Music.video,			
                           Music.jukebox, sep=""),
         aggAmbience = paste0(Ambience.romantic,
                              Ambience.intimate,		
                              Ambience.classy	,	
                              Ambience.hipster,		
                              Ambience.divey	,	
                              Ambience.touristy,		
                              Ambience.trendy	,	
                              Ambience.upscale,
                              Ambience.casual, sep=""),
         aggBestNights = paste0(BestNights.monday	 ,	
                                BestNights.tuesday		,	
                                BestNights.friday			,
                                BestNights.wednesday	,		
                                BestNights.thursday		,	
                                BestNights.sunday			,
                                BestNights.saturday, sep=""),
         aggGoodForMeal = paste0(GoodForMeal.dessert,		
                                 GoodForMeal.latenight,
                                 GoodForMeal.lunch		  ,	
                                 GoodForMeal.dinner		,	
                                 GoodForMeal.breakfast	,
                                 GoodForMeal.brunch, sep="")) %>% 
  select(-contains(".")) %>% 
  mutate_all(funs(str_replace_all(.,",+", ","))) %>% 
  mutate_all(funs(str_replace_all(., "[NA]+", "NA"))) %>% 
  mutate_all(funs(str_remove_all(., "\\.NA|NA\\."))) %>% 
  mutate_all(funs(str_replace_all(., "^\\.+$", "None"))) %>% 
  mutate_all(funs(str_remove_all(., "\\.+"))) %>% 
  mutate_all(funs(str_remove(.,"^,"))) %>% 
  mutate_all(funs(str_remove(.,",$")))

# turn "NA" into NA
food_attr_convert[food_attr_convert == "NA"] <- NA

### PROBLEM: too many collisions between variables - need to reduce to one value; don't want to eliminate too much information
### SOLUTION1: choose in order of frequency, low to high
### IMPLEMENTATION: iterate through, call function: if (numberofcommas + 1) > 1: split into vector, for each element in vector
### PROBLEM: if all slightly equal numbers but still collisions, some vals might not get seen

# min protocol: picks the least frequent value
pick_index_min <- function(freq_vect) {
  return(grep(min(freq_vect), freq_vect))
}

# max protocol: picks the most frequent value
pick_index_max <- function(freq_vect) {
  return(grep(max(freq_vect), freq_vect))
}

# prob protocol: picks the value probabilistically according to frequency so that
# same combinations of values aren't always the same
pick_index_prob <- function(freq_vect) {
  ord_vect <- sort(freq_vect)
  total <- reduce(freq_vect, sum)
  ord_vect_prob <- sapply(ord_vect, function(x) x/total)
  rev_vect_prob <- sort(ord_vect_prob, decreasing = TRUE)
  for (i in 2:length(rev_vect_prob)){
    rev_vect_prob[[i]] <- rev_vect_prob[[i]] + rev_vect_prob[[i-1]]
  }
  rand <- runif(1)
  ind <- which(sapply(rev_vect_prob, function (x) x > rand))[[1]]
  return(grep(ord_vect[[ind]],freq_vect))
}

# this function reduces a row of multiple values to a single value
# according to some protocol, in this case min
my_reduce <- function(col) {

  for (i in 1:length(col)) {
    val_list <- col[[i]]
    if (is.na(val_list) | val_list == "None" | !str_detect(val_list, ",")) {
      col[[i]] <- val_list
    } else {
      vals <- unlist(str_split(val_list, ","))
      freq_vect <- c()
      for (val in vals) {
        freq <- level_props %>%
          filter(attribute == val) %>%
          select(subtotal) %>%
          pull()
        freq_vect <- c(freq_vect, freq)
      }
      index <- pick_index_min(freq_vect)
      col[[i]] <- vals[index]
    }
  }
  return(col)
}

# apply the function
food_attr_reduce <- food_attr_convert %>% 
  mutate_all(funs(my_reduce))

```


```{r final-dataset}

# this puts together the significant columns we found with our new merged columns, drop NA's
food_attr_mod_2 <- food_attr %>% 
  cbind(food_attr_reduce) %>% 
  select(business_id, BusinessAcceptsCreditCards,RestaurantsPriceRange2,GoodForKids,BikeParking,Alcohol,HasTV,NoiseLevel,RestaurantsAttire,RestaurantsGoodForGroups,Caters,WiFi,RestaurantsReservations,RestaurantsTakeOut, aggBusinessParking, aggAmbience, aggGoodForMeal) %>% 
  drop_na()

# this function reduces a row of multiple values to a single value
# according to some protocol, in this case max
my_reduce_2 <- function(col) {

  for (i in 1:length(col)) {
    val_list <- col[[i]]
    if (is.na(val_list) | val_list == "None" | !str_detect(val_list, ",")) {
      col[[i]] <- val_list
    } else {
      vals <- unlist(str_split(val_list, ","))
      freq_vect <- c()
      for (val in vals) {
        freq <- category_counts %>%
          filter(categories == val) %>%
          select(n) %>%
          pull()
        freq_vect <- c(freq_vect, freq)
      }
      index <- pick_index_max(freq_vect)
      col[[i]] <- vals[index]
    }
  }
  return(col)
}

# reduce the categories variable
food$categories <- my_reduce_2(food$categories)

# pull the top 50 categories
large_categories_list <- food %>% 
  count(categories) %>% 
  arrange(desc(n)) %>% 
  head(50) %>% 
  pull(categories)

# filter by the top 50 categories
food_reduce <- food %>% 
  filter(categories %in% large_categories_list)

# merge the business info dataset with the business attributes 
food_reduce <- food_reduce %>% 
  inner_join(food_attr_mod_2, by = "business_id")

# turn character columns into factors
cols = c("Alcohol", "NoiseLevel", "RestaurantsAttire", "WiFi", "aggBusinessParking", "aggAmbience", "aggGoodForMeal", "categories")
food_reduce[cols] <- lapply(food_reduce[cols], factor)

# create training set
train_full <- food_reduce %>% 
  head(9*nrow(food_reduce)/10)

# create test set
test_full <- food_reduce %>% 
  tail(1*nrow(food_reduce)/10)

```

```{r linear regression}

#run linear analysis 
lm_food <- lm(stars ~ RestaurantsPriceRange2 + categories + BusinessAcceptsCreditCards + Alcohol +  HasTV + NoiseLevel +  RestaurantsGoodForGroups + Caters + WiFi + aggBusinessParking + aggAmbience + aggGoodForMeal + review_count + BikeParking + GoodForKids + RestaurantsReservations + RestaurantsTakeOut + RestaurantsAttire + RestaurantsGoodForGroups,data = food_reduce)

AIC(lm_food)
summary(lm_food)$adj.r.squared
```

```{r random_forest}

# run random forest
fit_full <- randomForest(stars ~  RestaurantsPriceRange2 + categories + BusinessAcceptsCreditCards + Alcohol +  HasTV + NoiseLevel +  RestaurantsGoodForGroups + Caters + WiFi + aggBusinessParking + aggAmbience + aggGoodForMeal + review_count + BikeParking + GoodForKids + RestaurantsReservations + RestaurantsTakeOut + RestaurantsAttire + RestaurantsGoodForGroups, 
                    data=train_full, 
                    importance=TRUE,  
                    ntree=50)

# inspect which elements are important
varImpPlot(fit_full)

# get r^2
(r2 <- rSquared(test_full$stars, test_full$stars - predict(fit_full, test_full)))

# plot learning curve
plot(fit_full)

# get info on model
fit_full

# predict values on test set
predict_tbl <- predict(fit_full, test_full) %>% 
  as.data.frame()

# modify predict_tbl
colnames(predict_tbl) <- c("predicted_score")
for (i in 1:nrow(predict_tbl)){
  predict_tbl[i,"index"] <-  i 
}

# find rows with highest predicted stars in test set
predict_tbl %>% 
  top_n(1, predicted_score) %>% 
  pull() %>% 
  test_full[.,] %>% 
  select(-business_id, -address, -postal_code, -latitude, -longitude, -is_open)

```


```{r random_forest_func}

# this function performs the above analysis for any subset of the dataset
random_forest <- function(x){
  food_reduce <- food_reduce %>% 
    filter(categories == x)

  cols = c("Alcohol", "NoiseLevel", "RestaurantsAttire", "WiFi", "aggBusinessParking", "aggAmbience", "aggGoodForMeal", "categories")
  food_reduce[cols] <- lapply(food_reduce[cols], factor)
  
  train_full <- food_reduce %>% 
    head(9*nrow(food_reduce)/10)
  
  test_full <- food_reduce %>% 
    tail(1*nrow(food_reduce)/10)
  
  fit_full <- randomForest(stars ~  RestaurantsPriceRange2 + categories + BusinessAcceptsCreditCards + Alcohol +  HasTV + NoiseLevel +  RestaurantsGoodForGroups + Caters + WiFi + aggBusinessParking + aggAmbience + aggGoodForMeal + review_count + BikeParking + GoodForKids + RestaurantsReservations + RestaurantsTakeOut + RestaurantsAttire + RestaurantsGoodForGroups , 
                      data=train_full, 
                      importance=TRUE,  
                      ntree=200)
  
  r2 <- round(rSquared(test_full$stars, test_full$stars - predict(fit_full, test_full)),3) %>% 
    as.data.frame()
  
  colnames(r2) <- "r.squared" 
    
  predict_tbl <- predict(fit_full, test_full) %>% 
  data.frame()

  colnames(predict_tbl) <- c("predicted_score")
  for (i in 1:nrow(predict_tbl)){
    predict_tbl[i,"index"] <-  i 
  }

  # find rows with highest predicted stars in test set
  predict_tbl <- predict_tbl %>% 
    top_n(3, predicted_score) 
  
  output <- predict_tbl %>% 
    pull(index) %>% 
    test_full[.,] %>% 
    select(-business_id, -address, -postal_code, -latitude, -longitude, -is_open) 

  plot(fit_full, main = x)
  
  return(cbind(predict_tbl[1], r2, output))
  #return(as.data.frame(r2))

}


#Apply the function random forest to each element of the vector large_categories_list
categories_rows <-large_categories_list[1:20]
best_row <- purrr::map_df(categories_rows,random_forest)
best_row %>% 
  arrange(desc(r.squared), desc(predicted_score)) %>% 
  select(categories, everything())
```











```{r}
convert <- function(col_name, tbl) {
  index <- grep(col_name, colnames(tbl))
  col <- tbl[index]
  col[!is.na(col)] <- paste0(col_name, ",")
  col[is.na(col)] <- ""
  return(col)
}


cols_eval <- function(col_names, tbl) {
  food_attr_local <- tbl
  index_vect = double()
  
  for (col_name in col_names) {
    j <- grep(col_name, colnames(tbl))
    index_vect <- append(index_vect, j)
  }
  food_attr_local <- food_attr_local[index_vect] %>% 
    as.data.frame()
  
  food_attr_local <- purrr::map(col_names, function(x) convert(x,tbl)) %>% 
  as.data.frame()
  
  i <<- i + 1
  
  result <- food_attr_local %>% 
    unite(attr,sep = "", remove = TRUE) %>% 
    count(attr) %>% 
    mutate(num_attr = str_count(attr, ","),
           opt_score = num_attr*n, 
           group = i) %>% 
    top_n(3, num_attr * n) %>% 
    arrange(desc(num_attr * n))
  return(result)
}


powerset <- function(vect) {
  total <- character()
  for (m in ((27 * length(vect)) %/% 30):length(vect)) {
    x <- combn(vect, m, simplify = FALSE)
    total <- append(total,x)
  }
  return(total)
}



find_best_cols <- function(tbl) {
  
  pwrset <- powerset(colnames(tbl))
  # for (test_col in pwrset){
  #   find_best_cols(test_col)
  # }
  i <<- 0
  final_lst <- list()
  for (test_cols_wrap in pwrset){
    for (test_cols in test_cols_wrap) {
      temp <- c()
      for (test_col in test_cols) {
        temp <- c(temp, test_col)
      }
    print(temp)
    final_lst <- list.append(final_lst,cols_eval(temp, tbl))
    }

  }
  final_df <- as.data.frame(do.call("rbind", final_lst)) %>% 
    distinct() %>%
    mutate(group = as.factor(group))
  
  #final <- map_df(pwrset, function(x) cols_eval(x, tbl))
  
  g <- final_df %>%
    ggplot(aes(num_attr, n, color = opt_score)) +
    geom_point(size = 4) +
    #scale_color_distiller(palette = "RdBu", type = "div", direction = 1)
    scale_color_distiller(palette = "OrRd", direction = 1) + 
    theme_minimal()

  print(g)
  
  return(final_df %>% 
    arrange(desc(opt_score)))
}



find_best_cols(food_attr_mod[c("RestaurantsPriceRange2", "GoodForKids")])

find_best_cols(food_attr_mod[24:28])
```



```{r}

### PLAN ###
# Create power set of all column names
# Create function that takes a list of column names
# Filter the attributes data set by list
# Calculate highest OPT score
# Increase number of attributes until OPT score goes down

convertxxxxxx <- function(col_name, tbl) {
  index <- grep(col_name, colnames(tbl))
  col <- tbl[index]
  col[!is.na(col)] <- paste0(col_name, ",")
  col[is.na(col)] <- ""
  return(col)
}

cols_eval <- function(col_names, tbl) {
  food_attr_local <- tbl
  index_vect = double()
  
  for (col_name in col_names) {
    j <- grep(col_name, colnames(tbl))
    index_vect <- append(index_vect, j)
  }
  food_attr_local <- food_attr_local[index_vect] %>% 
    as.data.frame()
  
  food_attr_local <- purrr::map(col_names, function(x) convert(x,tbl)) %>% 
  as.data.frame()
  
  i <<- i + 1
  
  result <- food_attr_local %>% 
    unite(attr,sep = "", remove = TRUE) %>% 
    count(attr) %>% 
    mutate(num_attr = str_count(attr, ","),
           opt_score = num_attr*n, 
           group = i) %>% 
    top_n(3, num_attr * n) %>% 
    arrange(desc(num_attr * n))
  return(result)
}


powerset2 <- function(vect) {
  total <- list(2^length(vect)-1)
  # m/2 -> m
  for (m in ((1*length(vect))%/%20):length(vect)) {
    x <- combn(vect,m)
    y <- split(x, rep(1:ncol(x), each = nrow(x)))
    total <- list.append(total,y)
  }
  #print(total)
  for (test_cols in total) {
    #print(test_cols)
      temp <- character(2^length(vect)-1)
      for (i in 1:length(test_cols)) {
        temp[[i]] <- test_cols[[i]]
        #print(test_col)
      }
    #print(temp)
  }
  #print(temp)
  return(temp)
} 

powerset5 <- function(vect) {
  total <- character(2^length(vect)-1)

  i <- 0
  for (m in 1:length(vect)) {
    x <- combn(vect, m, simplify = FALSE)
    for (j in 1:length(x)) {
      i <- i+1
      total[i] <- x[j]
    }
    #
    #total <- append(total,x)
  }
  return(total)
}
powerset <- function(vect) {
  total <- character()
  for (m in ((27 * length(vect)) %/% 30):length(vect)) {
    x <- combn(vect, m, simplify = FALSE)
    total <- append(total,x)
  }
  #print(total[[3]])
  return(total)
  
  # for (m in ((22 * length(vect)) %/% 26) : length(vect)) {
  #   x <- combn(vect, m, simplify = FALSE)
  #   
  #   total <- append(total,x)
  # }
  # return(total)
  # #print(total)
  # for (test_cols in total) {
  #   #print(test_cols)
  #     temp <- character(2^length(vect)-1)
  #     for (i in 1:length(test_cols)) {
  #       temp[[i]] <- test_cols[[i]]
  #       #print(test_col)
  #     }
  #   #print(temp)
  # }
  # #print(temp)
  # return(temp)
} 
##################
# system.time(val <- powerset(letters[1:10]))
# for (i in 100:110) {
#   valll <- val[[i]]
#   for (j in 1:length(valll)) {
#     print(valll[[j]])
#   }
# }


# TEST CASE
# cols_eval(c("GoodForKids", "RestaurantsGoodForGroups", "HasTV", "RestaurantsPriceRange2", "BusinessAcceptsCreditCards"), food_attr_mod)
# pwrset <- powerset(c("GoodForKids", "RestaurantsGoodForGroups", "HasTV", "RestaurantsPriceRange2", "BusinessAcceptsCreditCards")) 
# 
# result <- list()
# for (test_cols_wrap in pwrset){
#   for (test_cols in test_cols_wrap) {
#     temp <- c()
#     for (test_col in test_cols) {
#       temp <- c(temp, test_col)
#     }
#     result <- list.append(result,cols_eval(temp, food_attr_mod))
#   }
# }
# 
# resultdf <- as.data.frame(do.call("rbind", result))

find_best_cols <- function(tbl) {
  
  pwrset <- powerset(colnames(tbl))
  # for (test_col in pwrset){
  #   find_best_cols(test_col)
  # }
  i <<- 0
  final_lst <- list()
  for (test_cols_wrap in pwrset){
    for (test_cols in test_cols_wrap) {
      temp <- c()
      for (test_col in test_cols) {
        temp <- c(temp, test_col)
      }
    print(temp)
    final_lst <- list.append(final_lst,cols_eval(temp, tbl))
    }
    
    
  
  }
  final_df <- as.data.frame(do.call("rbind", final_lst)) %>% 
    distinct() %>%
    mutate(group = as.factor(group))
  
  #final <- map_df(pwrset, function(x) cols_eval(x, tbl))
  
  g <- final_df %>%
    ggplot(aes(num_attr, n, color = opt_score)) +
    geom_point(size = 4) +
    #scale_color_distiller(palette = "RdBu", type = "div", direction = 1)
    scale_color_distiller(palette = "OrRd", direction = 1) + 
    theme_minimal()

  print(g)
  
  return(final_df %>% 
    arrange(desc(opt_score)))
}

find_best_colsxxxx <- function(tbl) {
  
  pwrset <- powerset(colnames(tbl))
  #print(pwrset  )
  # for (test_col in pwrset){
  #   find_best_cols(test_col)
  # }
  i <<- 0
  final_lst <- list()
  for (test_cols_wrap in pwrset){
    for (test_cols in test_cols_wrap) {
      temp <- c()
      for (test_col in test_cols) {
        temp <- c(temp, test_col)
      }
    print(temp)
    final_lst <- list.append(final_lst,cols_eval(temp, tbl))
    }
    
    
  
  }
  final_df <- as.data.frame(do.call("rbind", final_lst)) %>% 
    distinct() %>%
    mutate(group = as.factor(group))
  
  #final <- map_df(pwrset, function(x) cols_eval(x, tbl))
  
  g <- final_df %>%
    ggplot(aes(num_attr, n, color = opt_score)) +
    geom_point(size = 4) +
    #scale_color_distiller(palette = "RdBu", type = "div", direction = 1)
    scale_color_distiller(palette = "OrRd", direction = 1) + 
    theme_minimal()

  print(g)
  
  return(final_df %>% 
    arrange(desc(opt_score)))
}

find_best_cols(food_attr_mod[c("RestaurantsPriceRange2", "GoodForKids")])

# This might take a while
find_best_cols(food_attr_mod[24:28])

# food_attr_mod
# 
# #### aggBusinessParking,aggAmbience,aggGoodForMeal,
# 
# 
# food_attr 
# 
# food_attr_mod_2 <- food_attr %>% 
#   select(-business_id) %>%
#   cbind(food_attr_reduce) %>% 
# #  select(-starts_with("Ambience"),-starts_with("GoodForMeal"),-starts_with("Music"),-starts_with("BusinessParking"), -starts_with("BestNights"),-ByAppointmentOnly, -CoatCheck, -RestaurantsCounterService, -Corkage, -ByAppointmentOnly, -AgesAllowed, -BusinessAcceptsBitcoin, -BYOB, -Open24Hours%>% 
#   select(BusinessAcceptsCreditCards,RestaurantsPriceRange2,GoodForKids,BikeParking,Alcohol,HasTV,NoiseLevel,RestaurantsAttire,RestaurantsGoodForGroups,Caters,WiFi,RestaurantsReservations,RestaurantsTakeOut, aggBusinessParking, aggAmbience, aggGoodForMeal) %>% 
# 
#   drop_na()

```



```{r rpart regression tree}


  fit <- rpart(stars ~ categories+BusinessAcceptsCreditCards+RestaurantsPriceRange2+GoodForKids+BikeParking+Alcohol+HasTV+NoiseLevel+RestaurantsAttire+RestaurantsGoodForGroups+Caters+WiFi+RestaurantsReservations+RestaurantsTakeOut+aggBusinessParking+aggAmbience+aggGoodForMeal, method = "anova", data = food_reduce)

printcp(fit) # display the results 
plotcp(fit) # visualize cross-validation results 
summary(fit) # detailed summary of splits

par(mfrow=c(1,2)) # two plots on one page 
rsq.rpart(fit) # visualize cross-validation results  

prune(fit, cp = 0.02)

plot(fit, uniform=TRUE, 
  	main="Regression Tree for Mileage ")
text(fit, use.n=TRUE, all=TRUE)

```






### EDA -- Katie
```{r}
library(mapdata)
library(maps)
library(klaR)
```
```{r}
which(food$address == "Green Valley Ranch Resort, 2309 Paseo Verde Pkwy")
food %>% 
  filter(longitude > 110)
```

```{r}
df <- na.omit(analysis)
df <- df %>% 
  mutate(RestaurantsPriceRange2 = case_when(
    RestaurantsPriceRange2 == 2 ~ "2",
    RestaurantsPriceRange2 == 1 ~ "1",
    RestaurantsPriceRange2 == 3 ~ "3",
    RestaurantsPriceRange2 == 4 ~ "4"
  ))
temp <- df[c(13,15)]
test <- kmodes(temp, 3, iter.max = 10, weighted = FALSE)
test
```
s